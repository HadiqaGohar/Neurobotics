"""
Graceful fallback mechanisms for authentication failures.
"""

import logging
import time
import asyncio
from typing import Dict, Any, Optional, Callable, List
from enum import Enum
from dataclasses import dataclass
from fastapi import Request, Response
from fastapi.responses import JSONResponse
import json

logger = logging.getLogger(__name__)


class FallbackStrategy(str, Enum):
    \"\"\"Fallback strategy types.\"\"\"\n    RETRY = \"retry\"\n    DEGRADE = \"degrade\"\n    REDIRECT = \"redirect\"\n    CACHE = \"cache\"\n    OFFLINE = \"offline\"\n    MAINTENANCE = \"maintenance\"\n\n\nclass ServiceStatus(str, Enum):\n    \"\"\"Service status levels.\"\"\"\n    HEALTHY = \"healthy\"\n    DEGRADED = \"degraded\"\n    UNHEALTHY = \"unhealthy\"\n    OFFLINE = \"offline\"\n    MAINTENANCE = \"maintenance\"\n\n\n@dataclass\nclass FallbackConfig:\n    \"\"\"Configuration for fallback mechanisms.\"\"\"\n    strategy: FallbackStrategy\n    max_retries: int = 3\n    retry_delay: float = 1.0\n    timeout: float = 30.0\n    cache_ttl: int = 300  # 5 minutes\n    redirect_url: Optional[str] = None\n    maintenance_message: Optional[str] = None\n    enable_offline_mode: bool = False\n\n\nclass CircuitBreaker:\n    \"\"\"Circuit breaker pattern implementation for auth services.\"\"\"\n    \n    def __init__(\n        self,\n        failure_threshold: int = 5,\n        recovery_timeout: int = 60,\n        expected_exception: type = Exception\n    ):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.expected_exception = expected_exception\n        \n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n    \n    def call(self, func: Callable, *args, **kwargs):\n        \"\"\"Execute function with circuit breaker protection.\"\"\"\n        \n        if self.state == \"OPEN\":\n            if self._should_attempt_reset():\n                self.state = \"HALF_OPEN\"\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            self._on_success()\n            return result\n        except self.expected_exception as e:\n            self._on_failure()\n            raise e\n    \n    async def call_async(self, func: Callable, *args, **kwargs):\n        \"\"\"Execute async function with circuit breaker protection.\"\"\"\n        \n        if self.state == \"OPEN\":\n            if self._should_attempt_reset():\n                self.state = \"HALF_OPEN\"\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = await func(*args, **kwargs)\n            self._on_success()\n            return result\n        except self.expected_exception as e:\n            self._on_failure()\n            raise e\n    \n    def _should_attempt_reset(self) -> bool:\n        \"\"\"Check if we should attempt to reset the circuit breaker.\"\"\"\n        return (\n            self.last_failure_time and\n            time.time() - self.last_failure_time >= self.recovery_timeout\n        )\n    \n    def _on_success(self) -> None:\n        \"\"\"Handle successful execution.\"\"\"\n        self.failure_count = 0\n        self.state = \"CLOSED\"\n    \n    def _on_failure(self) -> None:\n        \"\"\"Handle failed execution.\"\"\"\n        self.failure_count += 1\n        self.last_failure_time = time.time()\n        \n        if self.failure_count >= self.failure_threshold:\n            self.state = \"OPEN\"\n            logger.warning(f\"Circuit breaker opened after {self.failure_count} failures\")\n\n\nclass AuthServiceHealthChecker:\n    \"\"\"Health checker for authentication services.\"\"\"\n    \n    def __init__(self):\n        self.service_status = {\n            \"database\": ServiceStatus.HEALTHY,\n            \"jwt_service\": ServiceStatus.HEALTHY,\n            \"session_store\": ServiceStatus.HEALTHY,\n            \"rate_limiter\": ServiceStatus.HEALTHY,\n            \"email_service\": ServiceStatus.HEALTHY,\n        }\n        \n        self.last_check_time = {}\n        self.check_interval = 30  # 30 seconds\n        self.health_history = {}\n    \n    async def check_service_health(self, service_name: str) -> ServiceStatus:\n        \"\"\"Check health of a specific service.\"\"\"\n        \n        current_time = time.time()\n        last_check = self.last_check_time.get(service_name, 0)\n        \n        # Skip check if recently checked\n        if current_time - last_check < self.check_interval:\n            return self.service_status[service_name]\n        \n        try:\n            if service_name == \"database\":\n                status = await self._check_database_health()\n            elif service_name == \"jwt_service\":\n                status = await self._check_jwt_service_health()\n            elif service_name == \"session_store\":\n                status = await self._check_session_store_health()\n            elif service_name == \"rate_limiter\":\n                status = await self._check_rate_limiter_health()\n            elif service_name == \"email_service\":\n                status = await self._check_email_service_health()\n            else:\n                status = ServiceStatus.HEALTHY\n            \n            self.service_status[service_name] = status\n            self.last_check_time[service_name] = current_time\n            \n            # Record health history\n            if service_name not in self.health_history:\n                self.health_history[service_name] = []\n            \n            self.health_history[service_name].append({\n                \"timestamp\": current_time,\n                \"status\": status\n            })\n            \n            # Keep only recent history\n            self.health_history[service_name] = self.health_history[service_name][-100:]\n            \n            return status\n            \n        except Exception as e:\n            logger.error(f\"Health check failed for {service_name}: {e}\")\n            self.service_status[service_name] = ServiceStatus.UNHEALTHY\n            return ServiceStatus.UNHEALTHY\n    \n    async def _check_database_health(self) -> ServiceStatus:\n        \"\"\"Check database connectivity.\"\"\"\n        try:\n            # This would be implemented with actual database check\n            # For now, return healthy\n            return ServiceStatus.HEALTHY\n        except Exception:\n            return ServiceStatus.UNHEALTHY\n    \n    async def _check_jwt_service_health(self) -> ServiceStatus:\n        \"\"\"Check JWT service health.\"\"\"\n        try:\n            # Test JWT token creation and validation\n            from src.auth.better_auth import AuthService\n            test_token = AuthService.create_access_token(\"test_user\")\n            AuthService.verify_token(test_token, \"access\")\n            return ServiceStatus.HEALTHY\n        except Exception:\n            return ServiceStatus.UNHEALTHY\n    \n    async def _check_session_store_health(self) -> ServiceStatus:\n        \"\"\"Check session store health.\"\"\"\n        try:\n            # This would check Redis or database session store\n            return ServiceStatus.HEALTHY\n        except Exception:\n            return ServiceStatus.UNHEALTHY\n    \n    async def _check_rate_limiter_health(self) -> ServiceStatus:\n        \"\"\"Check rate limiter health.\"\"\"\n        try:\n            from src.security.security_utils import rate_limiter\n            # Test rate limiter functionality\n            rate_limiter.is_allowed(\"health_check\", 1, 1)\n            return ServiceStatus.HEALTHY\n        except Exception:\n            return ServiceStatus.UNHEALTHY\n    \n    async def _check_email_service_health(self) -> ServiceStatus:\n        \"\"\"Check email service health.\"\"\"\n        try:\n            # This would check email service connectivity\n            return ServiceStatus.HEALTHY\n        except Exception:\n            return ServiceStatus.DEGRADED  # Email is not critical\n    \n    def get_overall_health(self) -> ServiceStatus:\n        \"\"\"Get overall system health status.\"\"\"\n        statuses = list(self.service_status.values())\n        \n        if all(status == ServiceStatus.HEALTHY for status in statuses):\n            return ServiceStatus.HEALTHY\n        elif any(status == ServiceStatus.UNHEALTHY for status in statuses):\n            return ServiceStatus.UNHEALTHY\n        elif any(status == ServiceStatus.OFFLINE for status in statuses):\n            return ServiceStatus.OFFLINE\n        else:\n            return ServiceStatus.DEGRADED\n    \n    def get_health_report(self) -> Dict[str, Any]:\n        \"\"\"Get detailed health report.\"\"\"\n        return {\n            \"overall_status\": self.get_overall_health(),\n            \"services\": dict(self.service_status),\n            \"last_check_times\": dict(self.last_check_time),\n            \"check_interval\": self.check_interval,\n        }\n\n\nclass AuthFallbackManager:\n    \"\"\"Manages fallback mechanisms for authentication failures.\"\"\"\n    \n    def __init__(self):\n        self.health_checker = AuthServiceHealthChecker()\n        self.circuit_breakers = {}\n        self.fallback_configs = {}\n        self.cached_responses = {}\n        self.offline_mode = False\n        self.maintenance_mode = False\n        \n        # Default fallback configurations\n        self._setup_default_configs()\n    \n    def _setup_default_configs(self) -> None:\n        \"\"\"Set up default fallback configurations.\"\"\"\n        self.fallback_configs = {\n            \"login\": FallbackConfig(\n                strategy=FallbackStrategy.RETRY,\n                max_retries=3,\n                retry_delay=1.0,\n                timeout=10.0\n            ),\n            \"token_validation\": FallbackConfig(\n                strategy=FallbackStrategy.CACHE,\n                cache_ttl=300,\n                timeout=5.0\n            ),\n            \"user_profile\": FallbackConfig(\n                strategy=FallbackStrategy.CACHE,\n                cache_ttl=600,\n                timeout=5.0\n            ),\n            \"password_reset\": FallbackConfig(\n                strategy=FallbackStrategy.DEGRADE,\n                timeout=15.0\n            ),\n        }\n    \n    def get_circuit_breaker(self, service_name: str) -> CircuitBreaker:\n        \"\"\"Get or create circuit breaker for service.\"\"\"\n        if service_name not in self.circuit_breakers:\n            self.circuit_breakers[service_name] = CircuitBreaker()\n        return self.circuit_breakers[service_name]\n    \n    async def execute_with_fallback(\n        self,\n        operation_name: str,\n        primary_func: Callable,\n        fallback_func: Optional[Callable] = None,\n        *args,\n        **kwargs\n    ) -> Any:\n        \"\"\"Execute operation with fallback mechanisms.\"\"\"\n        \n        config = self.fallback_configs.get(operation_name, FallbackConfig(FallbackStrategy.RETRY))\n        circuit_breaker = self.get_circuit_breaker(operation_name)\n        \n        # Check if we're in maintenance mode\n        if self.maintenance_mode:\n            return self._handle_maintenance_mode(operation_name)\n        \n        # Check service health\n        service_health = await self.health_checker.check_service_health(\"database\")\n        if service_health == ServiceStatus.OFFLINE:\n            return await self._handle_offline_mode(operation_name, *args, **kwargs)\n        \n        # Try primary operation with circuit breaker\n        try:\n            if asyncio.iscoroutinefunction(primary_func):\n                result = await circuit_breaker.call_async(primary_func, *args, **kwargs)\n            else:\n                result = circuit_breaker.call(primary_func, *args, **kwargs)\n            \n            # Cache successful result if configured\n            if config.strategy == FallbackStrategy.CACHE:\n                self._cache_result(operation_name, args, kwargs, result, config.cache_ttl)\n            \n            return result\n            \n        except Exception as e:\n            logger.warning(f\"Primary operation {operation_name} failed: {e}\")\n            return await self._handle_fallback(operation_name, config, fallback_func, e, *args, **kwargs)\n    \n    async def _handle_fallback(\n        self,\n        operation_name: str,\n        config: FallbackConfig,\n        fallback_func: Optional[Callable],\n        error: Exception,\n        *args,\n        **kwargs\n    ) -> Any:\n        \"\"\"Handle fallback based on strategy.\"\"\"\n        \n        if config.strategy == FallbackStrategy.RETRY:\n            return await self._retry_operation(operation_name, config, error, *args, **kwargs)\n        \n        elif config.strategy == FallbackStrategy.CACHE:\n            cached_result = self._get_cached_result(operation_name, args, kwargs)\n            if cached_result is not None:\n                logger.info(f\"Using cached result for {operation_name}\")\n                return cached_result\n            \n            # If no cache, try fallback function\n            if fallback_func:\n                return await self._execute_fallback_func(fallback_func, *args, **kwargs)\n        \n        elif config.strategy == FallbackStrategy.DEGRADE:\n            return await self._handle_degraded_service(operation_name, fallback_func, *args, **kwargs)\n        \n        elif config.strategy == FallbackStrategy.REDIRECT:\n            return self._handle_redirect(config.redirect_url)\n        \n        elif config.strategy == FallbackStrategy.OFFLINE:\n            return await self._handle_offline_mode(operation_name, *args, **kwargs)\n        \n        # Default: re-raise the error\n        raise error\n    \n    async def _retry_operation(\n        self,\n        operation_name: str,\n        config: FallbackConfig,\n        original_error: Exception,\n        *args,\n        **kwargs\n    ) -> Any:\n        \"\"\"Retry operation with exponential backoff.\"\"\"\n        \n        for attempt in range(config.max_retries):\n            try:\n                await asyncio.sleep(config.retry_delay * (2 ** attempt))\n                \n                # This would need the original function reference\n                # For now, just log the retry attempt\n                logger.info(f\"Retrying {operation_name}, attempt {attempt + 1}/{config.max_retries}\")\n                \n                # In a real implementation, we'd retry the original function\n                # For now, raise the original error after all retries\n                if attempt == config.max_retries - 1:\n                    raise original_error\n                    \n            except Exception as e:\n                if attempt == config.max_retries - 1:\n                    logger.error(f\"All retry attempts failed for {operation_name}\")\n                    raise e\n                continue\n    \n    async def _execute_fallback_func(self, fallback_func: Callable, *args, **kwargs) -> Any:\n        \"\"\"Execute fallback function.\"\"\"\n        try:\n            if asyncio.iscoroutinefunction(fallback_func):\n                return await fallback_func(*args, **kwargs)\n            else:\n                return fallback_func(*args, **kwargs)\n        except Exception as e:\n            logger.error(f\"Fallback function also failed: {e}\")\n            raise e\n    \n    async def _handle_degraded_service(self, operation_name: str, fallback_func: Optional[Callable], *args, **kwargs) -> Any:\n        \"\"\"Handle degraded service mode.\"\"\"\n        logger.warning(f\"Service degraded for {operation_name}\")\n        \n        if fallback_func:\n            return await self._execute_fallback_func(fallback_func, *args, **kwargs)\n        \n        # Return a degraded response\n        return {\n            \"status\": \"degraded\",\n            \"message\": \"Service is currently degraded. Some features may not be available.\",\n            \"operation\": operation_name\n        }\n    \n    def _handle_redirect(self, redirect_url: str) -> JSONResponse:\n        \"\"\"Handle redirect fallback.\"\"\"\n        return JSONResponse(\n            status_code=302,\n            content={\"message\": \"Service temporarily unavailable\"},\n            headers={\"Location\": redirect_url}\n        )\n    \n    async def _handle_offline_mode(self, operation_name: str, *args, **kwargs) -> Any:\n        \"\"\"Handle offline mode.\"\"\"\n        logger.warning(f\"Operating in offline mode for {operation_name}\")\n        \n        # Check if we have cached data\n        cached_result = self._get_cached_result(operation_name, args, kwargs)\n        if cached_result is not None:\n            return cached_result\n        \n        # Return offline response\n        return {\n            \"status\": \"offline\",\n            \"message\": \"Service is currently offline. Please try again later.\",\n            \"operation\": operation_name,\n            \"retry_after\": 300  # 5 minutes\n        }\n    \n    def _handle_maintenance_mode(self, operation_name: str) -> JSONResponse:\n        \"\"\"Handle maintenance mode.\"\"\"\n        return JSONResponse(\n            status_code=503,\n            content={\n                \"status\": \"maintenance\",\n                \"message\": \"System is currently under maintenance. Please try again later.\",\n                \"operation\": operation_name\n            },\n            headers={\"Retry-After\": \"3600\"}  # 1 hour\n        )\n    \n    def _cache_result(self, operation_name: str, args: tuple, kwargs: dict, result: Any, ttl: int) -> None:\n        \"\"\"Cache operation result.\"\"\"\n        cache_key = self._generate_cache_key(operation_name, args, kwargs)\n        expiry_time = time.time() + ttl\n        \n        self.cached_responses[cache_key] = {\n            \"result\": result,\n            \"expiry_time\": expiry_time\n        }\n        \n        # Clean up expired cache entries\n        self._cleanup_cache()\n    \n    def _get_cached_result(self, operation_name: str, args: tuple, kwargs: dict) -> Any:\n        \"\"\"Get cached result if available and not expired.\"\"\"\n        cache_key = self._generate_cache_key(operation_name, args, kwargs)\n        \n        if cache_key in self.cached_responses:\n            cached_data = self.cached_responses[cache_key]\n            \n            if time.time() < cached_data[\"expiry_time\"]:\n                return cached_data[\"result\"]\n            else:\n                # Remove expired entry\n                del self.cached_responses[cache_key]\n        \n        return None\n    \n    def _generate_cache_key(self, operation_name: str, args: tuple, kwargs: dict) -> str:\n        \"\"\"Generate cache key for operation.\"\"\"\n        # Create a simple hash of the operation and parameters\n        import hashlib\n        \n        key_data = {\n            \"operation\": operation_name,\n            \"args\": str(args),\n            \"kwargs\": str(sorted(kwargs.items()))\n        }\n        \n        key_string = json.dumps(key_data, sort_keys=True)\n        return hashlib.md5(key_string.encode()).hexdigest()\n    \n    def _cleanup_cache(self) -> None:\n        \"\"\"Remove expired cache entries.\"\"\"\n        current_time = time.time()\n        expired_keys = [\n            key for key, data in self.cached_responses.items()\n            if current_time >= data[\"expiry_time\"]\n        ]\n        \n        for key in expired_keys:\n            del self.cached_responses[key]\n    \n    def enable_maintenance_mode(self, message: Optional[str] = None) -> None:\n        \"\"\"Enable maintenance mode.\"\"\"\n        self.maintenance_mode = True\n        logger.warning(\"Maintenance mode enabled\")\n    \n    def disable_maintenance_mode(self) -> None:\n        \"\"\"Disable maintenance mode.\"\"\"\n        self.maintenance_mode = False\n        logger.info(\"Maintenance mode disabled\")\n    \n    def enable_offline_mode(self) -> None:\n        \"\"\"Enable offline mode.\"\"\"\n        self.offline_mode = True\n        logger.warning(\"Offline mode enabled\")\n    \n    def disable_offline_mode(self) -> None:\n        \"\"\"Disable offline mode.\"\"\"\n        self.offline_mode = False\n        logger.info(\"Offline mode disabled\")\n    \n    def get_fallback_status(self) -> Dict[str, Any]:\n        \"\"\"Get current fallback system status.\"\"\"\n        return {\n            \"maintenance_mode\": self.maintenance_mode,\n            \"offline_mode\": self.offline_mode,\n            \"circuit_breakers\": {\n                name: {\n                    \"state\": cb.state,\n                    \"failure_count\": cb.failure_count,\n                    \"last_failure_time\": cb.last_failure_time\n                }\n                for name, cb in self.circuit_breakers.items()\n            },\n            \"cached_responses\": len(self.cached_responses),\n            \"health_status\": self.health_checker.get_health_report()\n        }\n\n\n# Global fallback manager instance\nfallback_manager = AuthFallbackManager()\n\n\n# Convenience functions\nasync def execute_with_fallback(operation_name: str, primary_func: Callable, fallback_func: Optional[Callable] = None, *args, **kwargs) -> Any:\n    \"\"\"Execute operation with fallback protection.\"\"\"\n    return await fallback_manager.execute_with_fallback(operation_name, primary_func, fallback_func, *args, **kwargs)\n\n\ndef enable_maintenance_mode(message: Optional[str] = None) -> None:\n    \"\"\"Enable maintenance mode.\"\"\"\n    fallback_manager.enable_maintenance_mode(message)\n\n\ndef disable_maintenance_mode() -> None:\n    \"\"\"Disable maintenance mode.\"\"\"\n    fallback_manager.disable_maintenance_mode()\n\n\ndef get_fallback_status() -> Dict[str, Any]:\n    \"\"\"Get fallback system status.\"\"\"\n    return fallback_manager.get_fallback_status()\n"